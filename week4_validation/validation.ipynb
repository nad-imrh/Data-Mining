{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw12QaXCH8ys"
      },
      "source": [
        "## NADILA IMAARAH 3323600015_D4 SAINS DATA TERAPAN A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4FWQ25WvH67l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0wp10JNH_Ik"
      },
      "source": [
        "## Membaca Dataset Titanic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oqqibE2fH67r",
        "outputId": "02ac704b-7d5f-4071-ce38-d09f8e5b845a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv(\"titanic.csv\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlK-9UcH67s"
      },
      "source": [
        "# Hold Out Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Membagi dataset dengan hold out method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4g36UrquH67u"
      },
      "outputs": [],
      "source": [
        "train_ho, test_ho = train_test_split(dataset, \n",
        "                                     test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "disini membagi dataset menjdadi data test dan data train dengan menggunakan metode hold out, dimana 30% dijadikan data tes dan 70% dijadikan data train\n",
        "\n",
        "kita menggunakan random_state agar urutan pengambilanya sama tidak berubah rubah"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_ho = train_ho[['Sex', 'Age', 'Pclass', 'Fare']].copy()\n",
        "test_data_ho = test_ho[['Sex', 'Age', 'Pclass', 'Fare']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "\n",
        "setelah membagi data train, di sini saya mengambil beberapa fitur saja yakni sex,age,pclass dan fare dari data train dan data tes yang telah di bagi, saya menggunakan copy agar tidak merusak data aslinya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Handling missing value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uGBgh47AH67v"
      },
      "outputs": [],
      "source": [
        "train_data_ho['Age'] = train_data_ho.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.mean()))\n",
        "test_data_ho['Age'] = test_data_ho.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "\n",
        "Disini saya mengisi missing value pada kolom age dengan rata-rata age berdasarkan kelas masing-masing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ci3en6fuH67v"
      },
      "outputs": [],
      "source": [
        "# Mengambil kolom 'Survived' sebagai target\n",
        "label_train_ho = train_ho[['Survived']]\n",
        "label_test_ho = test_ho[['Survived']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "\n",
        "jadi karena study case ini klasifikasi maka fitur target harus dipisahkan dulu agar model bisa belajar untuk bisa melakukan prediksi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ENCODING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>81.8583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>NaN</td>\n",
              "      <td>25.029098</td>\n",
              "      <td>3</td>\n",
              "      <td>7.8958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>11.1333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>NaN</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>27.7500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>NaN</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>26.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>NaN</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>7.6500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>NaN</td>\n",
              "      <td>37.893443</td>\n",
              "      <td>1</td>\n",
              "      <td>31.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>NaN</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>14.1083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>NaN</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>120.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>NaN</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>77.2875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>623 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sex        Age  Pclass      Fare\n",
              "445  NaN   4.000000       1   81.8583\n",
              "650  NaN  25.029098       3    7.8958\n",
              "172  NaN   1.000000       3   11.1333\n",
              "450  NaN  36.000000       2   27.7500\n",
              "314  NaN  43.000000       2   26.2500\n",
              "..   ...        ...     ...       ...\n",
              "106  NaN  21.000000       3    7.6500\n",
              "270  NaN  37.893443       1   31.0000\n",
              "860  NaN  41.000000       3   14.1083\n",
              "435  NaN  14.000000       1  120.0000\n",
              "102  NaN  21.000000       1   77.2875\n",
              "\n",
              "[623 rows x 4 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_ho[\"Sex\"] = train_data_ho[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "test_data_ho[\"Sex\"] = test_data_ho[\"Sex\"].map({\"male\": 0, \"female\": 1})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "\n",
        "selanjutnya melakukan encoding, karena metode klasifikasi tidak bisa langsung mengolah data teks jadi perlu dilakukan encoding, yang awalnya berupa teks menjadi numerik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Normalisasi dengan MinMax**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PWJ-IkMMH67w"
      },
      "outputs": [],
      "source": [
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_ho_scaled = scaler.fit_transform(train_data_ho)\n",
        "test_ho_scaled = scaler.transform(test_data_ho)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "\n",
        "Selanjutnya dilakukan normalisasi dengan menggunakan minmax agar skala setiap variabel berada rentang 0 hingga 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Mengklasifikasi dengan KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-t2y-INzH67x",
        "outputId": "0f020556-2392-4cb1-b1a5-356e35726d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error Ratio Hold-Out: 0.18656716417910446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nimaa\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(train_ho_scaled, label_train_ho)\n",
        "y_pred_ho = knn.predict(test_ho_scaled)\n",
        "error_ratio_ho = 1 - accuracy_score(label_test_ho, y_pred_ho)\n",
        "print(f\"Error Ratio Hold-Out: {error_ratio_ho}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "\n",
        "Selenjutnya membuat model knn dengan n sebanyak 3 yang artinya model akan memprediksi label data baru dengan melihat 3 tetangga terdekat, setelah itu melatih model knn dengan data train yang telah di scaled dan data label\n",
        "\n",
        "Kemudian menghitung akurasi antara prediksi dan label asli dan setelah itu mengihitung nilai error rasio yang didapatkan dari 1 di kurangi  akurasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A1TDMpVH67y"
      },
      "source": [
        "# K-Fold Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CXAb4v-NH67y",
        "outputId": "4c6a40b2-bda5-4d9a-a5cc-1e43c6dd77cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error Ratio K-Fold (k=10): 0.19189762796504367\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "error_ratios_kfold = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(dataset):\n",
        "    # Membagi dataset menjadi train dan test\n",
        "    train_kf, test_kf = dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
        "\n",
        "    # Mengambil fitur dan mengisi missing value Age dengan rata-rata berdasarkan Pclass\n",
        "    train_data_kf = train_kf[['Sex', 'Age', 'Pclass', 'Fare']].copy()\n",
        "    test_data_kf = test_kf[['Sex', 'Age', 'Pclass', 'Fare']].copy()\n",
        "\n",
        "    train_data_kf['Age'] = train_data_kf.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.mean()))\n",
        "    test_data_kf['Age'] = test_data_kf.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "    # Mengambil kolom 'Survived' sebagai label\n",
        "    label_train_kf = train_kf[['Survived']]\n",
        "    label_test_kf = test_kf[['Survived']]\n",
        "\n",
        "    #Encoding pada kolom sex\n",
        "    train_data_kf[\"Sex\"] = train_data_kf[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "    test_data_kf[\"Sex\"] = test_data_kf[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "    \n",
        "    # Normalisasi Min-Max\n",
        "    scaler = MinMaxScaler()\n",
        "    train_kf_scaled = scaler.fit_transform(train_data_kf)\n",
        "    test_kf_scaled = scaler.transform(test_data_kf)\n",
        "\n",
        "    # Klasifikasi K-NN dan menghitung error ratio\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(train_kf_scaled, label_train_kf.values.ravel())\n",
        "    y_pred_kf = knn.predict(test_kf_scaled)\n",
        "    error_ratio_kf = 1 - accuracy_score(label_test_kf, y_pred_kf)\n",
        "    error_ratios_kfold.append(error_ratio_kf)\n",
        "\n",
        "# Menghitung rata-rata error ratio\n",
        "mean_error_ratio_kfold = np.mean(error_ratios_kfold)\n",
        "print(f\"Error Ratio K-Fold (k=10): {mean_error_ratio_kfold}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analisis**\n",
        "tahapanya sama seperti sebelumnya yakni, Namun di sini metode untuk membagi datasetnya berbeda yakni dengan metode kfold. Kfold akan membagi dataset menjadi fold atau k bagian yang salin tidak tumpeng tindih. Disini dataset akan dibagi menjadi 10 bagian atau fold, setiap fold terdiri dari data yang acak. Pada iterasi pertama fold pertama akan digunakan untuk training dan fold 2 hingga 10 akan dijadikan testing, kemudian pada iterasi kedua fold kedua digunakan untuk training dan fold lainya dijadikan testing. proses ini diulang hingga semua fold telah digunakna sebagai data uji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rps_qipKH67z"
      },
      "source": [
        "# Leave-one-out Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9EvScPrcH67z",
        "outputId": "99fb5cf7-c744-422b-dae3-cd8e0f46fdae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error Ratio LOO: 0.19079685746352412\n"
          ]
        }
      ],
      "source": [
        "loo = LeaveOneOut()\n",
        "error_ratios_loo = []\n",
        "\n",
        "for train_idx, test_idx in loo.split(dataset):\n",
        "    # Membagi dataset menjadi train dan test\n",
        "    train_loo, test_loo = dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
        "\n",
        "    # Mengambil fitur dan mengisi missing value Age dengan rata-rata berdasarkan Pclass\n",
        "    train_data_loo = train_loo[['Sex', 'Age', 'Pclass', 'Fare']].copy()\n",
        "    test_data_loo = test_loo[['Sex', 'Age', 'Pclass', 'Fare']].copy()\n",
        "\n",
        "    train_data_loo['Age'] = train_data_loo.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.mean()))\n",
        "    test_data_loo['Age'] = test_data_loo['Age'].fillna(train_data_loo['Age'].mean())\n",
        "\n",
        "    # Mengambil kolom 'Survived' sebagai label\n",
        "    label_train_loo = train_loo[['Survived']]\n",
        "    label_test_loo = test_loo[['Survived']]\n",
        "\n",
        "    #Encoding pada kolom sex\n",
        "    train_data_loo[\"Sex\"] = train_data_loo[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "    test_data_loo[\"Sex\"] = test_data_loo[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "    \n",
        "     # Normalisasi Min-Max\n",
        "    scaler = MinMaxScaler()\n",
        "    train_loo_scaled = scaler.fit_transform(train_data_loo)\n",
        "    test_loo_scaled = scaler.transform(test_data_loo)\n",
        "\n",
        "    # Klasifikasi K-NN dan menghitung error ratio\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(train_loo_scaled, label_train_loo.values.ravel())\n",
        "    y_pred_loo = knn.predict(test_loo_scaled)\n",
        "    error_ratio_loo = 1 - accuracy_score(label_test_loo, y_pred_loo)\n",
        "    error_ratios_loo.append(error_ratio_loo)\n",
        "\n",
        "# Menghitung rata-rata error ratio\n",
        "mean_error_ratio_loo = np.mean(error_ratios_loo)\n",
        "print(f\"Error Ratio LOO: {mean_error_ratio_loo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ANALISIS**\n",
        "Namun di sini metode untuk membagi datasetnya berbeda yakni dengan metode leave one out cross validation.Metode ini bekerja dengan cara membagi dataset dengan setiap data dalam dataset digunakan 1 kalli sebagai data uji dan data lainya menjadi data testing, missal kita memiliki 100 data, maka LOO-CV akan melakukan 100 iterasi, di mana pada setiap iterasi, satu data point digunakan sebagai data uji, dan 99 data lainnya digunakan untuk pelatihan. \n",
        "\n",
        "setelah membagi dataset langkahnya sama seperti tahapan sebeelumnya  yakni mengisi missing value pada data age berdasarkan kelas masing-masing, kemudian memisahkan target, lalu melakukan encoding pada data yang awalnya string menjadi numerik dan juga melakukan normalisasi dengan metode yang sama yakni minmax\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
